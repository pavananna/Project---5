# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J2oPn4FnDDPAM8-kkvj9BD362A6PNc1C
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

d1=pd.read_excel(r"/content/drive/My Drive/Colab Notebooks/telcom_data.xlsx")   #to read the csv file

d1.head()

d1.info()

d1.shape

(d1.isnull().sum()/len(d1))*100

d1.drop(columns=["Nb of sec with 6250B < Vol UL < 37500B","TCP DL Retrans. Vol (Bytes)","TCP UL Retrans. Vol (Bytes)","HTTP DL (Bytes)","HTTP UL (Bytes)","Nb of sec with 125000B < Vol DL","Nb of sec with 1250B < Vol UL < 6250B","Nb of sec with 31250B < Vol DL < 125000B",'Last Location Name',"Nb of sec with 37500B < Vol UL","Nb of sec with 6250B < Vol DL < 31250B"],axis=1,inplace=True)

d1.shape

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(d1.isnull())
plt.show()

d1.dropna(inplace=True)

sns.heatmap(d1.isnull())
plt.show()

d1.isnull().sum()

d1.describe()

pd.set_option("display.max_rows",None)
pd.set_option("display.max_columns",None)

d1.describe()

d1.info()

import numpy as np
d1.replace("undefined",np.nan,inplace=True)

d1.isnull().sum()

columns=['Handset Manufacturer','Handset Type']
for i in columns:
  d1[i].fillna(value=d1[i].mode().iloc[0],inplace=True)

d1.isnull().sum().sum()

d1.duplicated().any()

d1.shape

#top 10 handsets used by the customers
top_10_handsets = d1['Handset Type'].value_counts().nlargest(10)
top_10_handsets

#top 3 handset manufacturers
top_3_manufacturers = d1['Handset Manufacturer'].value_counts().nlargest(3)
top_3_manufacturers

#top 5 handsets per top 3 handset manufacturer
top_5_handsets_per_manufacturer = {}
for manufacturer in top_3_manufacturers.index:
  top_5_handsets_per_manufacturer[manufacturer] = d1[d1['Handset Manufacturer'] == manufacturer]['Handset Type'].value_counts().nlargest(5)


#number of XDR  Unique Sessions
#let us consider each user has unique MSISDN number

d1.groupby('MSISDN/Number')['Bearer Id'].value_counts()

#Duration of each user
d1.groupby('MSISDN/Number')['Dur. (ms)'].sum()

#total uploaded data by each user
d1.groupby('MSISDN/Number')['Total UL (Bytes)'].sum()

#total downloaded data by each user
d1.groupby('MSISDN/Number')['Total DL (Bytes)'].sum()

#average RTT per customer
d1.groupby('MSISDN/Number')[['Avg RTT DL (ms)','Avg RTT UL (ms)']].mean()

#Handset type per custumor
d1.groupby('MSISDN/Number')['Handset Type'].unique()

d1.describe()

#handling outliers
columns=['Avg Bearer TP DL (kbps)','Avg Bearer TP UL (kbps)','Nb of sec with Vol UL < 1250B','Nb of sec with Vol DL < 6250B','Avg RTT DL (ms)']

import numpy as np
for x in columns:
    q1=np.quantile(d1[x],0.25)
    q3=np.quantile(d1[x],0.75)

    IQR=q3-q1

    upper_limit=q3+(1.5*IQR)
    lower_limit=q1-(1.5*IQR)

    d1.loc[d1[x] > upper_limit, x] = upper_limit
    d1.loc[d1[x] < lower_limit, x] = lower_limit

columns=d1[['Avg Bearer TP DL (kbps)','Avg Bearer TP UL (kbps)','Nb of sec with Vol UL < 1250B','Nb of sec with Vol DL < 6250B','Avg RTT DL (ms)']]
sns.boxplot(columns)
plt.xticks(rotation=60)
plt.show()

d1.info()

sns.histplot(data=d1,x="Total UL (Bytes)")
plt.show()

"""
Most of the data is sent between 3 to 5 byt"""

sns.histplot(data=d1,x="Total DL (Bytes)")
plt.show()

sns.histplot(data=d1,x="Other DL (Bytes)")
plt.show()

sns.histplot(data=d1,x="Other UL (Bytes)")
plt.show()

"""Finding Total Recevied Data and Sent Data"""

recvied_data_columns=['Total DL (Bytes)','Other DL (Bytes)','Gaming DL (Bytes)','Netflix DL (Bytes)','Youtube DL (Bytes)','Email DL (Bytes)','Google DL (Bytes)','Social Media DL (Bytes)','Nb of sec with Vol DL < 6250B','Activity Duration DL (ms)','DL TP > 1 Mbps (%)','Avg RTT DL (ms)','Avg Bearer TP DL (kbps)']

sent_data_columns=['Total DL (Bytes)','Other UL (Bytes)','Gaming UL (Bytes)','Netflix UL (Bytes)','Youtube UL (Bytes)','Email UL (Bytes)','Google UL (Bytes)','Social Media UL (Bytes)','Nb of sec with Vol UL < 1250B','Activity Duration UL (ms)','UL TP < 10 Kbps (%)','Avg Bearer TP UL (kbps)','Avg RTT UL (ms)']

Total_recevied_data=0
for i in recvied_data_columns:
  Total_recevied_data+=d1[i].sum()
print(Total_recevied_data)

total_sent_data=0
for i in sent_data_columns:
  total_sent_data+=d1[i].sum()
print(total_sent_data)

labels=np.array(['Recevied_data','Sent_data'])
explode=[0.03,0.03]
plt.pie(x=[Total_recevied_data,total_sent_data],labels=labels,explode=explode,autopct='%1.1f%%')
plt.show()

#Label Encoding
columns=['Handset Manufacturer','Handset Type']

from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
for i in columns:
  d1[i]=le.fit_transform(d1[i])

d1.info()

from sklearn.cluster import KMeans
X=d1.iloc[:,9:].values

wcss=[]

for i in range(1,11):
  kmeans=KMeans(n_clusters=i,init='k-means++',random_state=42)
  kmeans.fit(X)
  wcss.append(kmeans.inertia_)

#finding K value by using elbow method

sns.set()
plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

kmeans=KMeans(n_clusters=6,init='k-means++',random_state=42)
y_kmeans=kmeans.fit_predict(X)
print(y_kmeans)

kmeans=KMeans(n_clusters=3,init='k-means++',random_state=42)
y_kmeans=kmeans.fit_predict(X)
print(y_kmeans)

